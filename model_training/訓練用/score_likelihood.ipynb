{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CODE\\KD\\kdenv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "from cProfile import label\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "# from sklearnex import patch_sklearn  ## 加速svm\n",
    "# patch_sklearn(\"SVC\")\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve,roc_auc_score,recall_score,precision_recall_curve,auc,precision_score,f1_score,class_likelihood_ratios,accuracy_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.utils import resample,shuffle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "from learn_curving_fold import plot_learning_curves\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import shap\n",
    "import time\n",
    "import copy\n",
    "#from svm-gpu import SVM\n",
    "from IPython.display import display\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import trange\n",
    "from keras.layers import Dense, Conv2D, AveragePooling2D, MaxPooling2D, Flatten, Conv1D, AveragePooling1D, BatchNormalization\n",
    "from keras.layers.regularization.dropout import Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_self_score_up(\n",
    "    cv = 5,\n",
    "    model_path =None,\n",
    "    path = 'k_fold_train_validation_42',\n",
    "    random_state = 30,\n",
    "    ):\n",
    "    '''\n",
    "    cv : inter, default:5 -- input how many fold we want to do\n",
    "    model_path:default: None -- input the path that is been trained model\n",
    "    path: the folder for the datas\n",
    "    '''\n",
    "    specificity_list = []\n",
    "    f1_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    score = pd.DataFrame(columns=[])\n",
    "\n",
    "    for i in trange(1,cv+1):\n",
    "        score[f'{i}'] = []\n",
    "        fold_train = pd.read_csv(path+'/{}-fold_train_z.csv'.format(i))\n",
    "        fold_test = pd.read_csv(path+'/{}-fold_test_z.csv'.format(i))\n",
    "        #rename(消去columns項內非英文以及數字的解)\n",
    "        try:\n",
    "            fold_train = fold_train.drop(columns=['Unnamed: 0'])\n",
    "            fold_test = fold_test.drop(columns=['Unnamed: 0'])\n",
    "        except:\n",
    "            pass\n",
    "        fold_train = fold_train.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        fold_test = fold_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        ## upsampling train set \n",
    "        one_message = fold_train[fold_train[\"Class\"] == 1 ]\n",
    "        zero_message =fold_train[fold_train[\"Class\"] == 0]\n",
    "        one_message_up = resample(one_message,\n",
    "                    replace=True,\n",
    "                    n_samples=len(zero_message),\n",
    "                    random_state=42)\n",
    "        fold_train = pd.concat([one_message_up,zero_message])\n",
    "        fold_train = shuffle(fold_train,random_state = random_state)\n",
    "        fold_train= fold_train.reset_index(drop = True)\n",
    "        # set the train set for single fold\n",
    "        x_train = fold_train.drop(columns=['Class'])\n",
    "        y_train = fold_train['Class']       \n",
    "        ## set the non upsampling validation for the single fold\n",
    "        one_message_test = fold_test[fold_test[\"Class\"] == 1 ]\n",
    "        zero_message_test =fold_test[fold_test[\"Class\"] == 0]\n",
    "        one_message_up_test = resample(one_message_test,\n",
    "                    replace=True,\n",
    "                    n_samples=len(zero_message_test),\n",
    "                    random_state=42)\n",
    "        fold_test = pd.concat([one_message_up_test,zero_message_test])\n",
    "        fold_test = shuffle(fold_test,random_state = random_state)\n",
    "        fold_test= fold_test.reset_index(drop = True)         \n",
    "        x_test = fold_test.drop(columns=[\"Class\"])\n",
    "        y_test = fold_test['Class']\n",
    "        '============================================================='\n",
    "        model = joblib.load(model_path+f'/{i}-model')\n",
    "        y_pred = model.predict(x_test)\n",
    "        f1_list.append(f1_score(y_test, y_pred))\n",
    "        specificity_list.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        recall_list.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        precision_list.append(precision_score(y_test, y_pred))\n",
    "        likelihood = class_likelihood_ratios(y_test,y_pred)\n",
    "        positive_list.append(likelihood[0])\n",
    "        negative_list.append(likelihood[1])\n",
    "    score.loc['f1'] = f1_list\n",
    "    score.loc['precision'] = precision_list\n",
    "    score.loc['recall'] = recall_list\n",
    "    score.loc['specificity'] = specificity_list        \n",
    "    score.loc['positive likelihood']  = positive_list\n",
    "    score.loc['negative likelihood'] = negative_list\n",
    "    score['average'] = score.sum(axis = 1)/cv\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 20%|██        | 1/5 [00:00<00:00,  6.08it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 40%|████      | 2/5 [00:00<00:00,  6.51it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 60%|██████    | 3/5 [00:00<00:00,  6.86it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 80%|████████  | 4/5 [00:00<00:00,  6.74it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "100%|██████████| 5/5 [00:00<00:00,  6.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.884816</td>\n",
       "      <td>0.874482</td>\n",
       "      <td>0.882769</td>\n",
       "      <td>0.877766</td>\n",
       "      <td>0.870515</td>\n",
       "      <td>0.878069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.906379</td>\n",
       "      <td>0.900272</td>\n",
       "      <td>0.899375</td>\n",
       "      <td>0.904743</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>0.901554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.864255</td>\n",
       "      <td>0.850128</td>\n",
       "      <td>0.866765</td>\n",
       "      <td>0.852351</td>\n",
       "      <td>0.845547</td>\n",
       "      <td>0.855809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.910730</td>\n",
       "      <td>0.905826</td>\n",
       "      <td>0.903024</td>\n",
       "      <td>0.910260</td>\n",
       "      <td>0.902911</td>\n",
       "      <td>0.906550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive likelihood</th>\n",
       "      <td>9.681319</td>\n",
       "      <td>9.027237</td>\n",
       "      <td>8.937896</td>\n",
       "      <td>9.497954</td>\n",
       "      <td>8.709022</td>\n",
       "      <td>9.170685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative likelihood</th>\n",
       "      <td>0.149051</td>\n",
       "      <td>0.165453</td>\n",
       "      <td>0.147543</td>\n",
       "      <td>0.162206</td>\n",
       "      <td>0.171062</td>\n",
       "      <td>0.159063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            1         2         3         4         5  \\\n",
       "f1                   0.884816  0.874482  0.882769  0.877766  0.870515   \n",
       "precision            0.906379  0.900272  0.899375  0.904743  0.897003   \n",
       "recall               0.864255  0.850128  0.866765  0.852351  0.845547   \n",
       "specificity          0.910730  0.905826  0.903024  0.910260  0.902911   \n",
       "positive likelihood  9.681319  9.027237  8.937896  9.497954  8.709022   \n",
       "negative likelihood  0.149051  0.165453  0.147543  0.162206  0.171062   \n",
       "\n",
       "                      average  \n",
       "f1                   0.878069  \n",
       "precision            0.901554  \n",
       "recall               0.855809  \n",
       "specificity          0.906550  \n",
       "positive likelihood  9.170685  \n",
       "negative likelihood  0.159063  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'lgbm'\n",
    "path = \"D:/CODE/KD/code_after_web/data/Top5_under7(ByKeptGPT,with monocyte count)/k-fold/30\" \n",
    "model_path = f'D:/CODE/KD/code_after_web/output/Under 7/Top5_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "model_save_path = f'D:/CODE/KD/code_after_web/output/Under 7/Top5_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "score_up = kfold_self_score_up(path=path,model_path=model_path,random_state=30)\n",
    "score_up.to_csv(f'{model_save_path}/{model}_score_up_spe_validation_likelihood.csv')\n",
    "score_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_self_score(\n",
    "    cv = 5,\n",
    "    model_path =None,\n",
    "    path = 'k_fold_train_validation_42',\n",
    "    random_state = 30,\n",
    "    ):\n",
    "    '''\n",
    "    cv : inter, default:5 -- input how many fold we want to do\n",
    "    model_path:default: None -- input the path that is been trained model\n",
    "    path: the folder for the datas\n",
    "    '''\n",
    "    specificity_list = []\n",
    "    f1_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    accuracy = []\n",
    "    score = pd.DataFrame(columns=[])\n",
    "\n",
    "    for i in trange(1,cv+1):\n",
    "        score[f'{i}'] = []\n",
    "        fold_train = pd.read_csv(path+'/{}-fold_train_z.csv'.format(i))\n",
    "        fold_test = pd.read_csv(path+'/{}-fold_test_z.csv'.format(i))\n",
    "        #rename(消去columns項內非英文以及數字的解)\n",
    "        try:\n",
    "            fold_train = fold_train.drop(columns=['Unnamed: 0'])\n",
    "            fold_test = fold_test.drop(columns=['Unnamed: 0'])\n",
    "        except:\n",
    "            pass\n",
    "        fold_train = fold_train.rename(columns=lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        fold_test = fold_test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "         ## upsampling train set \n",
    "        one_message = fold_train[fold_train[\"Class\"] == 1 ]\n",
    "        zero_message =fold_train[fold_train[\"Class\"] == 0]\n",
    "        one_message_up = resample(one_message,\n",
    "                    replace=True,\n",
    "                    n_samples=len(zero_message),\n",
    "                    random_state=42)\n",
    "        fold_train = pd.concat([one_message_up,zero_message])\n",
    "        fold_train = shuffle(fold_train,random_state = random_state)\n",
    "        fold_train= fold_train.reset_index(drop = True)\n",
    "        ## set the train set for single fold\n",
    "        x_train = fold_train.drop(columns=['Class'])\n",
    "        y_train = fold_train['Class']\n",
    "        '=================================================================================='\n",
    "        ## set the non upsampling validation for the single fold\n",
    "        fold_test = shuffle(fold_test,random_state = random_state)\n",
    "        fold_test= fold_test.reset_index(drop = True)\n",
    "        x_test = fold_test.drop(columns=[\"Class\"])\n",
    "        y_test = fold_test['Class']\n",
    "        '============================================================='\n",
    "        model = joblib.load(model_path+f'/{i}-model')\n",
    "        y_pred = model.predict(x_test)\n",
    "        f1_list.append(f1_score(y_test, y_pred))\n",
    "        specificity_list.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        recall_list.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        precision_list.append(precision_score(y_test, y_pred))\n",
    "        likelihood = class_likelihood_ratios(y_test,y_pred)\n",
    "        accuracy.append(accuracy_score(y_test,y_pred))\n",
    "        positive_list.append(likelihood[0])\n",
    "        negative_list.append(likelihood[1])\n",
    "    score.loc['f1'] = f1_list\n",
    "    score.loc['precision'] = precision_list\n",
    "    score.loc['recall'] = recall_list\n",
    "    score.loc['specificity'] = specificity_list      \n",
    "    score.loc['positive likelihood']  = positive_list\n",
    "    score.loc['negative likelihood'] = negative_list\n",
    "    score.loc['accuracy'] = accuracy\n",
    "    score['average'] = score.sum(axis = 1)/cv\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 40%|████      | 2/5 [00:00<00:00, 15.45it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      " 80%|████████  | 4/5 [00:00<00:00, 12.89it/s]Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "100%|██████████| 5/5 [00:00<00:00, 13.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.419865</td>\n",
       "      <td>0.391660</td>\n",
       "      <td>0.396802</td>\n",
       "      <td>0.415292</td>\n",
       "      <td>0.407067</td>\n",
       "      <td>0.406137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.277061</td>\n",
       "      <td>0.254352</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>0.274257</td>\n",
       "      <td>0.267907</td>\n",
       "      <td>0.266128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.866460</td>\n",
       "      <td>0.851133</td>\n",
       "      <td>0.869427</td>\n",
       "      <td>0.854938</td>\n",
       "      <td>0.847059</td>\n",
       "      <td>0.857803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.910730</td>\n",
       "      <td>0.905826</td>\n",
       "      <td>0.903024</td>\n",
       "      <td>0.910260</td>\n",
       "      <td>0.902911</td>\n",
       "      <td>0.906550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive likelihood</th>\n",
       "      <td>9.706014</td>\n",
       "      <td>9.037903</td>\n",
       "      <td>8.965344</td>\n",
       "      <td>9.526788</td>\n",
       "      <td>8.724598</td>\n",
       "      <td>9.192129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative likelihood</th>\n",
       "      <td>0.146630</td>\n",
       "      <td>0.164344</td>\n",
       "      <td>0.144596</td>\n",
       "      <td>0.159363</td>\n",
       "      <td>0.169387</td>\n",
       "      <td>0.156864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            1         2         3         4         5  \\\n",
       "f1                   0.419865  0.391660  0.396802  0.415292  0.407067   \n",
       "precision            0.277061  0.254352  0.257062  0.274257  0.267907   \n",
       "recall               0.866460  0.851133  0.869427  0.854938  0.847059   \n",
       "specificity          0.910730  0.905826  0.903024  0.910260  0.902911   \n",
       "positive likelihood  9.706014  9.037903  8.965344  9.526788  8.724598   \n",
       "negative likelihood  0.146630  0.164344  0.144596  0.159363  0.169387   \n",
       "\n",
       "                      average  \n",
       "f1                   0.406137  \n",
       "precision            0.266128  \n",
       "recall               0.857803  \n",
       "specificity          0.906550  \n",
       "positive likelihood  9.192129  \n",
       "negative likelihood  0.156864  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'lgbm'\n",
    "path = \"D:/CODE/KD/code_after_web/data/Top5_under7(ByKeptGPT,with monocyte count)/k-fold/30\" \n",
    "model_path = f'D:/CODE/KD/code_after_web/output/Under 7/Top5_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "model_save_path = f'D:/CODE/KD/code_after_web/output/Under 7/Top5_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "score_up = kfold_self_score(path=path,model_path=model_path,random_state=30)\n",
    "score_up.to_csv(f'{model_save_path}/{model}_score_spe_validation_likelihood.csv')\n",
    "score_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_test_score(\n",
    "    best_model,\n",
    "    model_path =None,\n",
    "    file_test = 'k_fold_train_validation_42',\n",
    "    random_state = 30,\n",
    "    ):\n",
    "    '''\n",
    "    cv : inter, default:5 -- input how many fold we want to do\n",
    "    model_path:default: None -- input the path that is been trained model\n",
    "    path: the folder for the datas\n",
    "    '''\n",
    "    specificity_list = []\n",
    "    f1_list = []\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    accuracy = []\n",
    "\n",
    "    score = pd.DataFrame(columns=[])\n",
    "    score['test'] = []\n",
    "    fold_test = pd.read_csv(file_test)\n",
    "    #rename(消去columns項內非英文以及數字的解)\n",
    "    try:\n",
    "        fold_test = fold_test.drop(columns=['Unnamed: 0'])\n",
    "    except:\n",
    "        pass\n",
    "    '=================================================================================='\n",
    "    ## set the non upsampling validation for the single fold\n",
    "    fold_test = shuffle(fold_test,random_state = random_state)\n",
    "    fold_test= fold_test.reset_index(drop = True)\n",
    "    x_test = fold_test.drop(columns=[\"Class\"])\n",
    "    y_test = fold_test['Class']\n",
    "    '============================================================='\n",
    "    model = joblib.load(model_path+f'/{best_model}-model')\n",
    "    y_pred = model.predict(x_test)\n",
    "    f1_list.append(f1_score(y_test, y_pred))\n",
    "    specificity_list.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "    recall_list.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "    precision_list.append(precision_score(y_test, y_pred))\n",
    "    likelihood = class_likelihood_ratios(y_test,y_pred)\n",
    "    positive_list.append(likelihood[0])\n",
    "    negative_list.append(likelihood[1])\n",
    "    accuracy.append(accuracy_score(y_test,y_pred))\n",
    "\n",
    "    score.loc['f1'] = f1_list\n",
    "    score.loc['precision'] = precision_list\n",
    "    score.loc['recall'] = recall_list\n",
    "    score.loc['specificity'] = specificity_list      \n",
    "    score.loc['positive likelihood']  = positive_list\n",
    "    score.loc['negative likelihood'] = negative_list\n",
    "    score.loc['accuracy'] = accuracy\n",
    "\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.451520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.302913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.886364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.920610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive likelihood</th>\n",
       "      <td>11.164725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative likelihood</th>\n",
       "      <td>0.123436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          test\n",
       "f1                    0.451520\n",
       "precision             0.302913\n",
       "recall                0.886364\n",
       "specificity           0.920610\n",
       "positive likelihood  11.164725\n",
       "negative likelihood   0.123436\n",
       "accuracy              0.919327"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'lgbm'\n",
    "best_model_num = 3\n",
    "model_path = f'D:/CODE/KD/code_after_web/output/Under 7/KeptGPT_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "file_test = f'D:/CODE/KD/code_after_web/data/KeptGPT_under7(ByKeptGPT)/k-fold_monocyte_count/30/total-test_z-fold{best_model_num}.csv' \n",
    "model_save_path = f'D:/CODE/KD/code_after_web/output/Under 7/Top5_under7(ByKeptGPT,with monocyte count)/{model}'\n",
    "score_test = kfold_test_score(model_path = model_path,file_test=file_test,random_state = 30,best_model = best_model_num)\n",
    "##score_test.to_csv(f'{model_save_path}/score_test_likelihood.csv')\n",
    "score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive LR 10.739478114478082\n",
      "Negative LR 0.11160165847665925\n"
     ]
    }
   ],
   "source": [
    "recall = 0.897727272727272\n",
    "specificity = 0.91640866873065\n",
    "print(\"Positive LR\",recall/(1-specificity))\n",
    "print(\"Negative LR\",(1-recall)/specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPV: 0.9939393939393939 NPV: 0.1590909090909091\n",
      "P_LR: 6.527363184079602 N_LR: 0.21037668798862827\n",
      "recall: 0.8159203980099502 specificity: 0.875 precision: 0.9939393939393939\n",
      "accuracy 0.8181818181818182\n"
     ]
    }
   ],
   "source": [
    "# precision = 0.138009049773755\n",
    "# recall = 0.693181818181818\n",
    "# specificity = 0.831490490933215\n",
    "# TP = 1*recall\n",
    "# FN = 1-TP\n",
    "# FP = (TP-TP*precision)/precision\n",
    "# TN = (FP*specificity)/(1-specificity)\n",
    "\n",
    "TP=139\n",
    "FN=27\n",
    "FP=6\n",
    "TN=142\n",
    "\n",
    "PPV = (TP)/(TP+FP)\n",
    "NPV = (TN)/(FN+TN) \n",
    "\n",
    "FPR = (FP)/(TN+FP)\n",
    "TPR = (TP)/(TP+FN)\n",
    "FNR = (FN)/(TP+FN)\n",
    "TNR = (TN)/(TN+FP)\n",
    "accuracy = (TN+TP)/(TN+TP+FN+FP)\n",
    "\n",
    "print('PPV:',PPV,'NPV:',NPV)\n",
    "print('P_LR:',TPR/FPR,'N_LR:',FNR/TNR)\n",
    "print('recall:',TPR,'specificity:',TNR,'precision:',PPV)\n",
    "print('accuracy',accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kdenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
